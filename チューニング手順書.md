# 指標調整 実装計画書 v1（Codex 向け）

## 目的（今回のスコープ）

1. **露出検出の取りこぼし解消**（NudeNet ラベル表記ゆれ対応）
2. **`exposure_score` を [0,1] に正規化**（確率の直感と UI/ルール整合性の確保）
3. **NSFW 一般タグ辞書の一元化**（`rules.yaml` を唯一の権威に）
4. **WD14 の「弱い兆候」を拾う経路を追加**（`general_raw` / Top-K の活用）
5. **最低限の較正（Calibration）導線の実装**（温度スケーリング T を外部 JSON で適用）

> 参考（根拠）
> ・WD14 EVA02 v3 の推奨しきい値（P=R）: **0.5296**（モデルカード） ([Hugging Face][1])
> ・NudeNet ラベルは **`FEMALE_BREAST_EXPOSED` / `EXPOSED_BREAST_F`** など複数系統が併存（＝`startswith("EXPOSED_")` 固定は脆い） ([Dghs Img Utils][2])
> ・確率の結合は独立近似なら **和の補集合** `1-(1-p)(1-q)` が自然（包含排除の原理の特例） ([ウィキペディア][3])
> ・温度スケーリングは**単一パラメータ**で有効な後処理較正（Guo+ 2017） ([Proceedings of Machine Learning Research][4])
> ・較正の評価は **reliability diagram / calibration curve**（scikit-learn） ([scikit-learn][5])

---

## 変更一覧（概要）

* `app/rule_engine.py`

  * `*_max_exposed_detection()` の判定条件を **`"EXPOSED"` を含む & `"COVERED"` を含まない** へ変更（大文字小文字非依存）。
* `app/analysis_merge.py`

  * `compute_exposure_score()` を **確率の独立結合（和の補集合）** に変更し **[0,1] 保証**。
  * **NSFW 一般タグの唯一のソースを `rules.yaml.nsfw_general_tags` に統一**（`xsignals.yaml` の `nsfw_tags` はフォールバック扱い）。
  * `compute_placement_risk()` が **`wd14.general_raw` があれば優先**し、なければ従来の `general` を利用。
  * `--rules-config` オプションを追加（既定は `configs/rules.yaml`）。
* `app/analyzer_wd14.py` / `app/cli_wd14.py`

  * **`general_raw`（Top-Kの非閾値版）出力パス**を追加（少なくとも `rules.yaml.nsfw_general_tags` に含まれるタグを収集）。
* 新規 `app/calibration.py` + `scripts/calibrate_wd14.py`

  * **温度スケーリング**の適用ユーティリティと **T の推定 CLI**（最小実装）を追加。
  * `configs/calibration_wd14.json` が存在すれば **推論値へ適用**。

---

## 詳細タスク（手順とコード）

> 以降、**ユニファイド diff** か **置換用スニペット**を提示します。コンテキストは最小限です。失敗時は周辺に合わせてインデント・import を調整してください。

### 1) NudeNet 露出取りこぼし修正（rule_engine）

**目的**: `FEMALE_BREAST_EXPOSED` / `EXPOSED_BREAST_F` / `ANUS_EXPOSED` 等、**接頭辞や語順が異なる**ラベルをすべて拾う。`COVERED` を誤カウントしない。 ([Dghs Img Utils][2])

**修正ファイル**: `app/rule_engine.py`

```diff
--- a/app/rule_engine.py
+++ b/app/rule_engine.py
@@
-def _max_exposed_detection(nudity: Iterable[Mapping[str, Any]]) -> float:
-        max_score = 0.0
-        for det in nudity or []:
-            label = det.get("class", "") or ""
-            if label.startswith("EXPOSED_"):
-                score = float(det.get("score", 0.0))
-                if score > max_score:
-                    max_score = score
-        return max_score
+def _max_exposed_detection(nudity: Iterable[Mapping[str, Any]]) -> float:
+        """
+        Return max score among *exposed* detections, robust to label variants:
+        e.g. 'FEMALE_BREAST_EXPOSED' / 'EXPOSED_BREAST_F' / 'ANUS_EXPOSED'.
+        We exclude any label containing 'COVERED'.
+        """
+        max_score = 0.0
+        for det in nudity or []:
+            label = str(det.get("class", "") or "").upper()
+            if "EXPOSED" in label and "COVERED" not in label:
+                score = float(det.get("score", 0.0))
+                if score > max_score:
+                    max_score = score
+        return max_score
```

**DoD**:

* ユニットテストで `FEMALE_BREAST_EXPOSED` / `EXPOSED_BREAST_F` / `BREAST_COVERED` を混ぜた配列から **最大スコアのみ**が返る。

---

### 2) `exposure_score` を確率合成に変更（analysis_merge）

**目的**: 現状の **加算**は 1 を超えうる。**独立近似の和の補集合**で **[0,1]** に正規化。 ([ウィキペディア][3])

**修正ファイル**: `app/analysis_merge.py`

```diff
--- a/app/analysis_merge.py
+++ b/app/analysis_merge.py
@@
 def compute_exposure_score(
     detections: list[NudityDetection],
     thresholds: dict,
     weights: dict,
 ) -> float:
@@
-    strong_component = (max(strong_scores) if strong_scores else 0.0) * float(weights.get("strong_weight", 1.0))
-    weak_component = (max(weak_scores) if weak_scores else 0.0) * float(weights.get("weak_weight", 0.6))
-    return round(strong_component + weak_component, 6)
+    # maxima
+    p_strong = max(strong_scores) if strong_scores else 0.0
+    p_weak   = max(weak_scores)   if weak_scores   else 0.0
+    w_s = float(weights.get("strong_weight", 1.0))
+    w_w = float(weights.get("weak_weight", 0.6))
+    # scale & clamp
+    p_s = max(0.0, min(p_strong * w_s, 1.0))
+    p_w = max(0.0, min(p_weak   * w_w, 1.0))
+    # independent-union approx => stays in [0,1]
+    combined = 1.0 - (1.0 - p_s) * (1.0 - p_w)
+    return round(combined, 6)
```

**DoD**:

* ランダム 1,000 画像で `exposure_score ∈ [0,1]` を統計確認（例: assert 0.0 <= x <= 1.0）。

---

### 3) NSFW 辞書を `rules.yaml` に一元化（analysis_merge）

**目的**: 前処理（analysis）と評価（rule_engine）で異辞書を参照する**二重管理を廃止**。唯一の参照先を `rules.yaml.nsfw_general_tags` に統一。

**変更点**:

* `analysis_merge.py` に `--rules-config` を追加して `rules.yaml` を読み込む。
* `placement_cfg` に `nsfw_tags` を注入して `compute_placement_risk()` に渡す。
* `compute_placement_risk()` は引数 `cfg['nsfw_tags']`（存在しなければデフォルト）を使用。

```diff
--- a/app/analysis_merge.py
+++ b/app/analysis_merge.py
@@
-    parser.add_argument("--xsignals-config", type=Path, default=Path("configs/xsignals.yaml"))
+    parser.add_argument("--xsignals-config", type=Path, default=Path("configs/xsignals.yaml"))
+    parser.add_argument("--rules-config", type=Path, default=Path("configs/rules.yaml"))
@@
-    nudenet_cfg = load_yaml(args.nudenet_config)
-    xsignals_cfg = load_yaml(args.xsignals_config)
-    try:
-        rules_cfg = load_yaml(Path("configs/rules.yaml"))
+    nudenet_cfg = load_yaml(args.nudenet_config)
+    xsignals_cfg = load_yaml(args.xsignals_config)
+    try:
+        rules_cfg = load_yaml(args.rules_config)
     except FileNotFoundError:
         rules_cfg = {}
@@
-    placement_cfg = xsignals_cfg.get("placement_risk_pre", {})
+    placement_cfg = xsignals_cfg.get("placement_risk_pre", {})
@@
-    nsfw_tags = set(rules_cfg.get("nsfw_general_tags", []))
+    nsfw_tags = set(rules_cfg.get("nsfw_general_tags", []))
+    if nsfw_tags:
+        # inject unified dictionary (fallback to xsignals if empty)
+        placement_cfg = dict(placement_cfg)
+        placement_cfg["nsfw_tags"] = sorted(nsfw_tags)
@@
-        placement_risk = compute_placement_risk(wd14_payload, exposure_score, placement_cfg)
+        placement_risk = compute_placement_risk(wd14_payload, exposure_score, placement_cfg)
```

**DoD**:

* `rules.yaml` の `nsfw_general_tags` 数が `xsignals.yaml` より多い場合でも、P2 出力の `xsignals.nsfw_general_sum` / `placement_risk_pre` が**増分反映**される。

---

### 4) WD14 の raw 経路（弱い兆候の取り込み）

**目的**: `general_threshold` を下げずに弱い NSFW 兆候を評価へ**穏当に反映**する。
**方針**: p1（WD14 出力）に **`general_raw`（Top-K / あるいは辞書）** を追加し、p2 側で `general_raw` があれば**それを優先**して `compute_placement_risk()` の一般タグ寄与を計算する。

#### 4.1 `analyzer_wd14.py` 変更（出力拡張）

**やること**: 既存の推論ベクトルから**全スコア**を取り出し、

* `rules.yaml.nsfw_general_tags` に含まれるタグは**無条件で収集**
* * 任意 `TOPK_RAW_GENERAL` の上位タグを追加
    を `general_raw` として返す。

**目安**: `TOPK_RAW_GENERAL=64` 程度（可変）。

> 参考: EVA02 v3 モデルカードに P=R 閾値 0.5296 の記載。運用は**目的により閾値可変**だが、まずは **raw 併用**で弱信号を拾う道を用意。 ([Hugging Face][1])

**実装スケッチ（抜粋）**:

```python
# analyzer_wd14.py の推論関数内、row: np.ndarray（generalスコア配列）
from typing import List, Tuple

def build_general_raw(row: np.ndarray, names: List[str], nsfw_whitelist: set[str], topk: int = 64) -> list[tuple[str, float]]:
    pairs = [(names[i], float(row[i])) for i in range(len(names))]
    # NSFWホワイトリストは必ず含める
    keep = {name for name in nsfw_whitelist}
    # 上位topkを追加
    top = sorted(pairs, key=lambda x: x[1], reverse=True)[:topk]
    for n, s in top:
        keep.add(n)
    # 出力ペア
    out: List[Tuple[str, float]] = []
    for n in keep:
        idx = names.index(n) if n in names else -1
        if idx >= 0:
            out.append((n, float(row[idx])))
    return sorted(out, key=lambda x: x[1], reverse=True)
```

* `WD14Prediction`（あるいは p1 の JSON シリアライズ部）に `general_raw` フィールドを追加。

#### 4.2 `cli_wd14.py` 変更（JSONL に `general_raw` を書き出し）

* 既存 `rating` / `general` に加え `general_raw` を JSON に含める。
* 構築時に `rules.yaml` を読み、`nsfw_general_tags` を `nsfw_whitelist` として渡す。

#### 4.3 `analysis_merge.py` 変更（raw 優先）

```diff
--- a/app/analysis_merge.py
+++ b/app/analysis_merge.py
@@ def compute_placement_risk(...):
-    general_tags = wd14.get("general", [])
+    general_tags = wd14.get("general_raw", wd14.get("general", []))
```

**DoD**:

* `general_raw` が存在すればそれを使い、無ければ従来通り `general` を使う（後方互換）。
* `nsfw_general_sum`（rule_engine 側の集計）にも `general_raw` の寄与が間接的に到達（p1→p2→p3）。

---

### 5) 温度スケーリング適用の導線（最小）

**目的**: WD14 の確率歪みを**後処理で補正**できる構造を先に用意（学習データが揃い次第 T を推定）。

* 理論背景: **温度スケーリングは実務で有効な確率較正**（logit に 1/T を掛ける）。 ([Proceedings of Machine Learning Research][4])
* 評価: **Calibration curve / Reliability diagram** を確認（scikit-learn）。 ([scikit-learn][5])

#### 5.1 新規ファイル `app/calibration.py`

```python
# app/calibration.py
from __future__ import annotations
import json, math, pathlib
from typing import Dict

EPS = 1e-6

def _logit(p: float) -> float:
    p = min(max(p, EPS), 1.0 - EPS)
    return math.log(p / (1.0 - p))

def _sigmoid(z: float) -> float:
    return 1.0 / (1.0 + math.exp(-z))

def apply_temperature(p: float, T: float) -> float:
    # temperature scaling in probability space via logits
    return _sigmoid(_logit(p) / max(T, EPS))

def load_calibration(path: pathlib.Path) -> Dict:
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except FileNotFoundError:
        return {}

def apply_wd14_calibration(wd14: dict, calib: Dict) -> dict:
    # rating
    rating = wd14.get("rating", {})
    for k, v in list(rating.items()):
        T = float(calib.get("rating", {}).get(k, 1.0))
        rating[k] = apply_temperature(float(v), T)
    wd14["rating"] = rating
    # general / general_raw
    for key in ("general_raw", "general"):
        items = wd14.get(key)
        if not items:
            continue
        out = []
        for item in items:
            if isinstance(item, (list, tuple)) and len(item) == 2:
                tag, score = item
            elif isinstance(item, dict):
                tag, score = item.get("name"), item.get("score")
            else:
                continue
            T = float(calib.get("general_tags", {}).get(str(tag), 1.0))
            out.append((tag, apply_temperature(float(score), T)))
        wd14[key] = out
    return wd14
```

#### 5.2 `analysis_merge.py` で較正を適用（存在すれば）

```diff
--- a/app/analysis_merge.py
+++ b/app/analysis_merge.py
@@
+from .calibration import load_calibration, apply_wd14_calibration
@@
-    nudenet_cfg = load_yaml(args.nudenet_config)
+    nudenet_cfg = load_yaml(args.nudenet_config)
     xsignals_cfg = load_yaml(args.xsignals_config)
@@
+    calib = load_calibration(Path("configs/calibration_wd14.json"))
@@ バッチ/ループ内 (wd14_payload を使う直前)
-        placement_risk = compute_placement_risk(wd14_payload, exposure_score, placement_cfg)
+        wd14_payload = apply_wd14_calibration(wd14_payload, calib)
+        placement_risk = compute_placement_risk(wd14_payload, exposure_score, placement_cfg)
```

#### 5.3 T 推定 CLI（最小雛形）

**新規** `scripts/calibrate_wd14.py`（二値タグ用・最小）

* 入力: `out/p1_wd14.jsonl` + ラベル CSV（`phash,tag,gt`）
* 出力: `configs/calibration_wd14.json`

> 評価用可視化は **scikit-learn の CalibrationDisplay** を推奨（任意）。 ([scikit-learn][6])

---

## テスト計画

### 単体テスト（pytest）

1. **露出検出**: `EXPOSED_BREAST_F`/`FEMALE_BREAST_EXPOSED`/`BREAST_COVERED` 混在で `exposure_detection == max(EXPOSED*)`。
2. **露出スコア範囲**: 強=0.9, 弱=0.9, w=(1.0,0.6) → `exposure_score = 1 - (1-0.9)*(1-0.54)=0.954` など、**常に [0,1]**。
3. **辞書一元化**: `rules.yaml.nsfw_general_tags` に `nude/topless` などを追加し、`placement_risk_pre` と `nsfw_general_sum` が増える。
4. **raw 優先**: `wd14.general_raw` を与えた場合に `general` を無視して Top-K から計算される。
5. **較正適用**: `calibration_wd14.json` で `bikini: T=1.2` を与えると `score` が**減衰**（T>1 でソフト化）する。 ([Proceedings of Machine Learning Research][4])

### スモーク（パイプライン）

* 既存データで `p0→p1→p2→p3` を一巡。
* `out/p2_analysis.jsonl` の各 `xsignals.exposure_score ∈ [0,1]`。
* カード UI の `exposure_peak = max(exposure_score, exposure_detection)` が過去より**上振れ**しやすい（取りこぼし解消の副作用）。

---

## 設定変更・互換性

* `configs/xsignals.yaml` の `placement_risk_pre.nsfw_tags` は**フォールバック**（将来的に削除予定）。
* **唯一の権威**は `configs/rules.yaml.nsfw_general_tags`。
* `configs/calibration_wd14.json` は**任意**（存在しなければ無視）。
* 既存のしきい値（`rules.yaml.thresholds.*`）は**変更なし**。

---

## 完了の定義（DoD）

* [ ] `exposure_score` が **全件で [0,1]**。
* [ ] `rule_engine` が `FEMALE_BREAST_EXPOSED` 系で **exposure_detection を正しく拾う**。
* [ ] `placement_risk_pre` が **`rules.yaml.nsfw_general_tags` に同期**（`xsignals.yaml` の変更不要）。
* [ ] `p1` に `general_raw` が入る（存在すれば `p2` で優先）。
* [ ] `configs/calibration_wd14.json` が無い場合でも**動作は従来同等**。
* [ ] pytest が追加分を含めて**Green**。

---

## ロールバック指針

* `exposure_score` の正規化で検出感度が下がった場合、

  * 一時的に **`weak_weight` を上げる**（例: 0.6→0.75）か、
  * `compute_exposure_score()` を `sum` と `prob_or` の**トグル**にする（フラグで切替）。
* `general_raw` が運用に重い場合は p1 の出力を**OFF**にし、p2 は自動的に `general` フォールバック。

---

## 付録：実装上メモ（根拠リンク）

* **WD14 EVA02 v3**（P=R 推奨閾値 0.5296）: モデルカード参照。 ([Hugging Face][1])
* **NudeNet ラベル**の系統差（`FEMALE_BREAST_EXPOSED` と `EXPOSED_BREAST_F` 等）: 実装例・ドキュメントに両系統が存在。 ([Dghs Img Utils][2])
* **確率の結合**（独立仮定での和の補集合）: 包含排除原理の n=2 の特例。 ([ウィキペディア][3])
* **温度スケーリング**（単一パラメータでの確率較正）: Guo+ 2017。 ([Proceedings of Machine Learning Research][4])
* **較正の可視化**（Calibration curve / Reliability diagram）: scikit-learn。 ([scikit-learn][5])

---

[1]: https://huggingface.co/SmilingWolf/wd-eva02-large-tagger-v3?utm_source=chatgpt.com "SmilingWolf/wd-eva02-large-tagger-v3 · Hugging Face"
[2]: https://dghs-imgutils.deepghs.org/v0.14.0/api_doc/detect/nudenet.html?utm_source=chatgpt.com "imgutils.detect.nudenet — imgutils 0.14.0 documentation"
[3]: https://en.wikipedia.org/wiki/Inclusion%E2%80%93exclusion_principle?utm_source=chatgpt.com "Inclusion–exclusion principle"
[4]: https://proceedings.mlr.press/v70/guo17a?utm_source=chatgpt.com "On Calibration of Modern Neural Networks"
[5]: https://scikit-learn.org/stable/modules/calibration.html?utm_source=chatgpt.com "1.16. Probability calibration — scikit-learn 1.7.2 documentation"
[6]: https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibrationDisplay.html?utm_source=chatgpt.com "CalibrationDisplay — scikit-learn 1.7.2 documentation"
